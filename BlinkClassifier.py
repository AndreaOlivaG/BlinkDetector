# -*- coding: utf-8 -*-
"""Práctica final Deep Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VLFdorXEuRIAdNhMIqbOxFSpiZG3Nr-q

#**IMPORTACIÓN DEL *DATASET* Y ACTUALIZACIÓN DE LIBRERÍA**#

En primer lugar, se realiza la conexión con Google Drive y se descomprime el archivo *zip*.
"""

from google.colab import drive
drive.mount('/content/drive')
!unzip -n '/content/drive/MyDrive/RT-BENE.zip' >> /dev/null

"""Se debe actualizar *tensorflow* a la versión 2.11.0 para poder utilizar el parámetro *apply_class_balancing* de la función de pérdidas *BinaryFocalCrossentropy*.\
Después de actualizar, **se debe reiniciar el entorno de ejecución**.
"""

import tensorflow as tf

if tf.__version__ != '2.11.0':
  !pip uninstall tensorflow
  !pip install tensorflow

"""#**CÓDIGO GENERAL**#

Se importan todas las librerías necesarias.
"""

import os
import scipy
import random
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

from sklearn import metrics
from sklearn.metrics import auc
from sklearn.utils import class_weight
from tensorflow.keras import optimizers
from tensorflow.keras import applications
from sklearn.metrics import confusion_matrix
from tensorflow.keras.losses import BinaryFocalCrossentropy
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.optimizers import RMSprop, Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import f1_score, accuracy_score, classification_report, auc, roc_curve
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, MaxPool2D, Input, Concatenate, RandomFlip, RandomRotation, RandomBrightness, GlobalAveragePooling2D

"""Se establece la ruta de las imágenes y se eliminan las columnas que no son necesarias.\
También se establecen las dimensiones de las imágenes (60x36x3) y se fija la semilla para permitir la reproducibilidad de los experimentos.
"""

path = "/content/RT-BENE/"
imgs_path = path + "images"
data = pd.read_csv(path + "blinks.csv", dtype = {'blink':'str'})
data.drop('blink_id', axis = 1, inplace = True)
data.drop('video', axis = 1, inplace = True)

left_eye_col = 'left_eye'
right_eye_col = 'right_eye'
y_col = 'blink'

batch_size = 128
img_width = 60
img_height = 36

seed = 43
os.environ['PYTHONHASHSEED'] = str(seed)
np.random.seed(seed)
random.seed(seed)
tf.random.set_seed(seed)

input_shape = (img_width, img_height, 3)

"""Se llevan a cabo dos particiones del conjunto de datos. En la primera, que parte del conjunto de datos original, se separa un 70% para *train*.\
Del 30% restante, una mitad es para *validation* y la otra para *test*.
"""

train_data, test_data = train_test_split(data, test_size = 0.3, random_state = seed)
dev_data, test_data = train_test_split(test_data, test_size = 0.5, random_state = seed)

train_data = train_data.reset_index(drop = True)
dev_data = dev_data.reset_index(drop = True)
test_data = test_data.reset_index(drop = True)

test_labels = test_data['blink'].astype('int32')

"""Se puede observar que hay muchas menos imágenes de ojos cerrados que de ojos abiertos debido a la velocidad con la que se produce un parpadeo y a que la mayor parte del tiempo los ojos están abiertos.\
Esto produce un desbalanceo de datos, lo que puede llevar a un sesgo en las predicciones.
"""

data.groupby('blink').count()

"""A continuación, se define el generador *custom* que devuelve dos imágenes.\
Se ha dedidido añadir el parámetro *shuffle* a la función *generator* dado que no se quiere que  se mezclen las instancias en el generador de *test*, puesto que las etiquetas se obtendrán de la propia partición de *test* en lugar de *test_generator*.


"""

datagen = ImageDataGenerator(rescale = 1./255)

def generator(dataframe, shuffle):
  left_eye_generator = datagen.flow_from_dataframe(dataframe = dataframe,
                                                   directory = imgs_path,
                                                   target_size = (img_width, img_height),
                                                   x_col = left_eye_col,
                                                   y_col = y_col,
                                                   class_mode = "binary",
                                                   seed = seed,
                                                   shuffle = shuffle,
                                                   batch_size = batch_size)

  right_eye_generator = datagen.flow_from_dataframe(dataframe = dataframe,
                                                    directory = imgs_path,
                                                    target_size = (img_width, img_height),
                                                    x_col = right_eye_col,
                                                    y_col = y_col,
                                                    class_mode = "binary",
                                                    seed = seed,
                                                    shuffle = shuffle,
                                                    batch_size = batch_size)

  while True:
    left_eye = left_eye_generator.next()
    left_eye_image = left_eye[0]
    label = left_eye[1]
    right_eye = right_eye_generator.next()
    right_eye_image = right_eye[0]
    yield[left_eye_image, right_eye_image], label

"""Se crea el generador de imágenes para la fase entrenamiento (*train_generator*), que a su vez hará uso del generador de validación (*dev_generator*). Para la fase de prueba, se crea el generador *test_generator*."""

train_generator = generator(train_data, True)
dev_generator = generator(dev_data, True)
test_generator = generator(test_data, False)

"""Asimismo, se obtienen los pesos de cada clase (*blink=0* y *blink=1*) dado que, debido al desbalanceo del *dataset*, se tendrá en cuenta a la hora de entrenar en algún experimento.\
Se puede observar cómo se ha dado más peso a la clase *blink=1*, que es la que menor número de instancias posee.
"""

class_weights = dict(enumerate(class_weight.compute_class_weight(
    class_weight = "balanced",
    classes = np.unique(train_data['blink']),
    y = train_data['blink']
    )))

class_weights

"""Por último, se define la función para representar de manera gráfica el valor de la función de pérdidas en cada *epoch*."""

def plot_history(history):
    plt.figure()
    plt.xlabel('Epoch')
    plt.ylabel('Binary focal crossentropy')
    plt.plot(history.epoch, np.array(history.history['loss']), label='Train Loss')
    plt.legend()
    plt.ylim([0, max(history.history['loss'])])

"""#**RED NEURONAL CONVOLUCIONAL PARTIENDO DE CERO**#

##**DEFINICIÓN DE LA ARQUITECTURA**##

Dado que la entrada son dos imágenes, se crean dos capas de Input y se concatenan. \\
También se añaden al modelo varias capas de convolución y de *pooling*, así como una *flatten* y dos redes completamente conectadas, siendo la última de ellas de una única unidad puesto que se trata de un problema de clasificación binaria.
"""

left = Input(shape = input_shape)
right = Input(shape = input_shape)

merged = Concatenate(axis = 1)([left, right])
conv_1 = Conv2D(16, 3, activation = 'relu', input_shape = input_shape)(merged)
mp_1 = MaxPooling2D()(conv_1)
conv_2 = Conv2D(32, 3, activation = 'relu')(mp_1)
mp_2 = MaxPooling2D()(conv_2)
conv_3 = Conv2D(64, 3, activation = 'relu')(mp_2)
mp_3 = MaxPooling2D()(conv_3)
flatten = Flatten()(mp_3)
dense_1 = Dense(512, activation  = 'relu')(flatten)
output = Dense(1, activation = 'sigmoid')(dense_1)

model = Model(inputs = [left, right], outputs = output)
model.summary()

"""También se puede representar de forma gráfica la arquitectura de la red:"""

tf.keras.utils.plot_model(model)

"""La función de pérdidas es *BinaryFocalCrossentropy*, la cual permite forzar el balanceo de clases. El valor del resto de sus hiperparámetros se mantienen por defecto.\
El optimizador es *Adam* y la tasa de aprendizaje es 0.001, y la métrica es *Accurary*. Una vez se tengan las predicciones, se calculará el valor de la métrica *F1-Score*.
"""

model.compile(loss = BinaryFocalCrossentropy(apply_class_balancing = True),
              optimizer = Adam(learning_rate = 0.001),
              metrics = ['Accuracy'])

"""##**ENTRENAMIENTO, EVALUACIÓN Y PREDICCIÓN**##

Se entrena el modelo final propuesto.
"""

history = model.fit(train_generator,
                    epochs = 3,
                    verbose = 1,
                    steps_per_epoch = len(train_data)/batch_size,
                    validation_data = dev_generator,
                    validation_steps = len(dev_data)/batch_size)

model.evaluate(test_generator,
               steps = len(test_data)/batch_size,
               verbose = 1)

"""Se vuelve a llamar al generador porque en el *evaluate* anterior ya se utilizó.\
Se realiza la predicción de las imágenes de *test*, y se obtiene un reporte con varias métricas, entre ellas *F1-Score*, cada una con sus diferentes *averages*.\
Por otro lado, se obtienen los valores de la matriz de confusión: *true negatives*, *false positives*, *false negatives* y *true positives*.
"""

test_generator = generator(test_data, False)
preds = model.predict(test_generator, steps = len(test_data)/batch_size).round().astype('int32')[:,0]

print("\n", classification_report(test_labels, preds, digits = 4))
tn, fp, fn, tp = confusion_matrix(test_labels, preds).ravel()
print("\nTN:", tn)
print("FP:", fp)
print("FN:", fn)
print("TP:", tp)

"""##**GRÁFICAS**##

En la siguiente gráfica se puede ver el valor de la función de pérdidas en cada una de las tres *epoch*. Se puede ver que el error va disminuyendo según se van llevando a cabo más iteraciones de entrenamiento.
"""

print("Máximo error:", max(np.array(history.history['loss'])))
print("Mínimo error:", min(np.array(history.history['loss'])))
plot_history(history)

"""También se puede visualizar la curva ROC. La línea punteada representa un hipotético modelo donde la mitad de las instancias se clasifican correctamente, mientras que la azul representa el modelo entrenado."""

fpr, tpr, thresholds_keras = roc_curve(test_labels, preds)
auc = auc(fpr, tpr)

plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label='Modelo (area = {:.3f})'.format(auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc = 'best')
plt.show()

"""#**RED NEURONAL CONVOLUCIONAL PARTIENDO DE UN MODELO PRE-ENTRENADO**#

##**DEFINICIÓN DE LA ARQUITECTURA**##

Se define la arquitectura para esta red neuronal convolucional.\
En primer lugar, se crean las dos capas de entrada, una por cada ojo del fotograma, y se concatenan. Seguidamente, se carga el modelo *DenseNet121* entrenado con *ImageNet* y se establece que el tensor de entrada sea la capa concatenada anterior. También se establece que las capas de este modelo pre-entrenado no se puedan entrenar.\
Por último, se crean nuevas capas para adaptar el modelo al problema de esta práctica y se crea el modelo final.
"""

left = Input(shape = input_shape)
right = Input(shape = input_shape)
merged = Concatenate(axis = 1)([left, right])

pretrained_model = applications.DenseNet121(weights = 'imagenet',
                                            include_top = False,
                                            input_tensor = merged)

for layer in pretrained_model.layers:
    layer.trainable = False

x = GlobalAveragePooling2D()(pretrained_model.output)
x = Dense(512, activation = 'relu')(x)
predictions = Dense(1, activation = 'sigmoid')(x)

model = Model(inputs = [left, right], outputs = predictions)
model.summary()

tf.keras.utils.plot_model(model)

"""Al igual que en el anterior modelo propuesto, la función de pérdidas es *BinaryFocalCrossentropy*, aplicando balanceo de clases, y el optimizador es *Adam*, con tasa de aprendizaje de 0.001."""

model.compile(loss = BinaryFocalCrossentropy(apply_class_balancing = True),
              optimizer = Adam(learning_rate = 0.001),
              metrics = ['Accuracy'])

"""##**ENTRENAMIENTO, EVALUACIÓN Y PREDICCIÓN**##

Se entrena el modelo final propuesto.
"""

history = model.fit(train_generator,
                    epochs = 3,
                    verbose = 1,
                    steps_per_epoch = len(train_data)/batch_size,
                    validation_data = dev_generator,
                    validation_steps = len(dev_data)/batch_size)

model.evaluate(test_generator,
               steps = len(test_data)/batch_size,
               verbose = 1)

test_generator = generator(test_data, False)
preds = model.predict(test_generator, steps = len(test_data)/batch_size).round().astype('int32')[:,0]

print("\n", classification_report(test_labels, preds, digits = 4))
tn, fp, fn, tp = confusion_matrix(test_labels, preds).ravel()
print("\nTN:", tn)
print("FP:", fp)
print("FN:", fn)
print("TP:", tp)

"""##**GRÁFICAS**##"""

print("Máximo error:", max(np.array(history.history['loss'])))
print("Mínimo error:", min(np.array(history.history['loss'])))
plot_history(history)

fpr, tpr, thresholds_keras = roc_curve(test_labels, preds)
auc = metrics.auc(fpr, tpr)

plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr, label = 'Model (area = {:.3f})'.format(auc))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc = 'best')
plt.show()

"""#**CELDAS AUXILIARES**#"""

#GUARDAR MODELO
from keras.models import model_from_json
model_json = model.to_json()
with open("model.json", "w") as json_file:
  json_file.write(model_json)
model.save_weights("model.h5")
print("Modelo guardado en el PC")

#CARGAR MODELO
from keras.models import model_from_json
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
model = model_from_json(loaded_model_json)
model.load_weights("model.h5")
print("Modelo cargado desde el PC")

#OTRA FORMA DE HACER LAS PREDICCIONES
preds_1 = []
steps = len(test_data)/batch_size
aux = 0
test_generator = generator(test_data, False)

for data, label in test_generator:
  if aux < steps:
    for i in range(len(data[0])):
      left = tf.expand_dims(data[0][i], axis = 0)
      right = tf.expand_dims(data[1][i], axis = 0)
      preds_1.append(model.predict([left, right], verbose=0).round().astype('int32')[0][0])
    aux += 1
  else:
    break

print(classification_report(test_labels, preds_1))

f1 = f1_score(test_labels, preds_1, average = 'macro')
acc = accuracy_score(test_labels, preds_1)
print("f1-score: %.4f, accuracy: %.4f" % (f1, acc))